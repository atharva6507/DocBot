{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3005503-3231-4e8a-9649-b54f865f0f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb4d4238-a381-45b4-8803-bf7229c79624",
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"***************************************\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "550de610-69a5-40e7-8eb0-e7e7479cad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fd1d280-e2d9-4a15-9724-a889b9b9bf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_text(docs):\n",
    "    text = \"\"\n",
    "    for doc in docs:\n",
    "        reader = PdfReader(doc)\n",
    "        for page in reader.pages:\n",
    "            text += page.extract_text()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f177c2ed-5fb8-466f-99f2-5aba629c7f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_chunks(text):\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=10000, chunk_overlap=1000)\n",
    "    chunks = splitter.split_text(text)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86fbdd5c-8523-4880-a135-5c9440230eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector_store(chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\",google_api_key=\"***************************************\")\n",
    "    vector_store = FAISS.afrom_texts(texts=chunks, embedding=embeddings)\n",
    "    vector_store.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3c17a8b9-b5d8-4f69-a34a-f50326a14c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26763c5-0703-43c9-9d16-f1f3468840de",
   "metadata": {},
   "outputs": [],
   "source": [
    "nest_asyncio.apply()\n",
    "\n",
    "def get_vector_store(chunks):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(\n",
    "        model=\"models/embedding-001\",\n",
    "        google_api_key=\"***************************************\"\n",
    "    )\n",
    "\n",
    "    async def create_store():\n",
    "        # Await the coroutine to resolve it properly\n",
    "        vector_store = await FAISS.afrom_texts(texts=chunks, embedding=embeddings)\n",
    "        vector_store.save_local(\"faiss_index\")  # Save the index locally\n",
    "        return vector_store\n",
    "\n",
    "    # Run the coroutine directly in the existing event loop\n",
    "    return asyncio.ensure_future(create_store())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2dbb760-9992-4113-9cf9-c70366a34192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conversational_chain():\n",
    "    prompt_template = \"\"\"\n",
    "    Answer the question as detailed as possible from the provided context, make sure to provide answer from provided context only,\n",
    "    if answer is not available, just say \"Answer not available\", don't provide wrong answers.\n",
    "    Context:\\n {context}?\\n\n",
    "    Question:\\n {question}\\n\n",
    "\n",
    "    Answer:\\n\\n\n",
    "    \"\"\"\n",
    "    model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\",temperature=0.2, api_key=\"***************************************\")\n",
    "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\",\"question\"])\n",
    "    chain = load_qa_chain(model, chain_type=\"stuff\", prompt=prompt)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55db8963-db9d-422f-9a77-0afce0197af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_input(user_question):\n",
    "    embeddings = GoogleGenerativeAIEmbeddings(model = \"models/embedding-001\", google_api_key=\"***************************************\")\n",
    "    \n",
    "    new_db = FAISS.load_local(\"faiss_index\", embeddings, allow_dangerous_deserialization=True)\n",
    "    docs = new_db.similarity_search(user_question)\n",
    "\n",
    "    chain = get_conversational_chain()\n",
    "\n",
    "    \n",
    "    response = chain(\n",
    "        {\"input_documents\":docs, \"question\": user_question}\n",
    "        , return_only_outputs=True)\n",
    "\n",
    "    print(response[\"output_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6b8531f-615c-402f-83cd-cf005d7839ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_docs = [\"7181-attention-is-all-you-need.pdf\",\"neural models in nlp.pdf\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8eba840a-eb18-4ee2-9f9f-24aa9cce2c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Task pending name='Task-2' coro=<get_vector_store.<locals>.create_store() running at C:\\Users\\Atharva Raut\\AppData\\Local\\Temp\\ipykernel_26320\\2112239331.py:9>>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text = get_pdf_text(pdf_docs)\n",
    "text_chunks = get_text_chunks(raw_text)\n",
    "get_vector_store(text_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "447e41fe-b10e-4f7f-9e1b-69acfae2bcc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-derivative saliency is a strategy inspired by back-propagation in vision.  It measures how much each input unit contributes to the final decision by approximating the class score (Sc(e)) with a linear function of e using the first-order Taylor expansion: Sc(e) â‰ˆ w(e)Te + b, where w(e) is the derivative of Sc with respect to the embedding e.  The magnitude (absolute value) of the derivative indicates the sensitivity of the final decision to a change in a particular dimension, showing how much that dimension contributes to the final decision.  The saliency score is then given by S(e) = |w(e)|.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_input(\"Explain First Derivative Saliency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528b6bf9-0e07-4dae-936a-d0b7af0ed783",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c23811-2bed-428c-8dd4-b8988a948b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793fb4f-c27e-4c76-9f88-4db7909b2354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8ad8c-8cf9-485f-8eac-0a5a1734565f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac8569c-ecd5-4ef6-b2ad-f12496d68e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc2e7a-5cfa-430c-8066-edba3f1de507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7b6414-e74a-4674-93f7-be90d78a5b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
